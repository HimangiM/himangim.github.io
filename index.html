<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Himangi Mittal</title>
  
  <meta name="author" content="Himangi Mittal">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/profile-pic.png">
</head>

<body>
  <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Himangi Mittal</name>
              </p>
              <p>I am a first year Master of Science in Robotics <a href="https://www.ri.cmu.edu/education/academic-programs/master-of-science-robotics/">(MSR)</a> student 
                in the <a href="https://www.ri.cmu.edu/">Robotics Institute (RI)</a> at <a href="https://www.cmu.edu/">Carnegie Mellon University (CMU)</a>, working with <a href="http://www.cs.cmu.edu/~abhinavg/">Prof. Abhinav Gupta</a>. Previously, I worked as a Research Assistant at CMU with 
                <a href="https://davheld.github.io/">Prof. David Held</a> at the <a href="https://r-pad.github.io/">R-Pad Lab</a>, in collaboration with Pittsburgh-based autonomous driving company, 
                <a href="https://labs.ri.cmu.edu/argo-ai-center/">Argo AI</a>. My research interests include Computer Vision, Robotics, and Machine Learning.
              </p>
              <p>
                At CMU, I work on self-supervised algorithms for 3D LiDAR point clouds. I did my bachelors from
                <a href="http://www.jiit.ac.in/">Jaypee Institute of Information Technology, Noida, India</a> where I worked with 
                <a href="http://www.jiit.ac.in/dr-anuja-arora">Dr. Anuja Arora</a>.
                
              </p>
              <p style="text-align:center">
                <a href="mailto:himangimittal@gmail.com">Email</a> &nbsp/&nbsp
                <a href="">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=n8Fc_w4AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/HimangiMittal">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/HimangiM">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/himangimittal/">Linkedin</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile-pic.png"><img style="width:80%;max-width:80%" alt="profile photo" src="images/profile-pic.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <ul>
                <li> <b> Oct 2021 : </b> Paper accepted at BMVC 2021 <font color="red">(Oral)</font>.
                <li> <b> Apr 2021 - Dec 2021: </b> I will be serving as a reviewer for ICCV 2021, AAAI 2022, WACV 2022, and CVPR 2022.
                <li> <b> Aug 2021: </b> Journal paper accepted in PAA (in collaboration with Robert Bosch, India).
                <li> <b> Feb 2021: </b> Accepted as a MSR student at CMU for Fall 2021.
                <li> <b> July 2020: </b> Presented a short paper at RSS Workshop on Self-Supervised Robot Learning 2020.
                <li> <b> Feb 2020: </b> Paper accepted at CVPR 2020 <font color="red">(Oral)</font>.
                <li> <b> Dec 2019: </b> Paper accepted at International Conference on Big Data Analytics (BDA) 2019.
                <li> <b> Aug 2019: </b> Started working as a Full-time Research Assistant at CMU.
                <li> <b> May 2018: </b> Started working as a Summer Research Intern at Robert Bosch, Bangalore, India. 
                <li> <b> Oct 2017: </b> Paper accepted at CODS-COMAD 2018.
                <li> <b> May 2017: </b> Started working as a Summer Research Intern at Indian Institute of Technology, Hyderabad, India (IIT-H).
              <ul>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
               I am interested in devising self-supervised algorithms to minimize the need of large amounts of annotated data required for the training for 
               supervised algorithms. 
              </p>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
          <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
             <div class="one">
                <div class="two" id='bmvc_image'>
                    <a href="images/Tweet 2.gif"><img style="width:140%;max-width:140%" alt="profile photo" src="images/Tweet 2.gif" class="hoverZoomLink"></a>
              </div>
            </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
              <papertitle>Self-Supervised Point Cloud Completion via Inpainting</papertitle>
              </a>
              <br>
              <strong>Himangi Mittal</strong>,
              <a href="https://www.ri.cmu.edu/ri-people/brian-e-okorn/">Brian Okorn</a>,
              <a href='https://www.linkedin.com/in/arpit-jangid/'>Arpit Jangid</a>
              <a href="http://davheld.github.io/">David Held</a>,
              <br>
              <em>BMVC</em> 2021 <font color="red">(Oral)</font>
              <br>
              <a href="https://arxiv.org/abs/2111.10701">Arxiv</a> \
              <a href="https://www.bmvc2021-virtualconference.com/assets/papers/0443.pdf">Paper</a> \
              <a href="https://www.bmvc2021-virtualconference.com/conference/papers/paper_0443.html">Conference Presentation</a>
              <p></p>
              <p>A self-supervised method to complete the incomplete, partial point clouds for real-world settings like LiDAR where ground truth complete point cloud
              annotations are unavailable. We achieve this via inpainting where a region of the point cloud is removed and the network is trained to complete this removed region.</p>
            </td>
          </tr>
          
          <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='prl_image'>
                    <a href="images/PRL-Graphical-Abstract.png"><img style="width:140%;max-width:140%" alt="profile photo" src="images/PRL-Graphical-Abstract.png" class="hoverZoomLink"></a>
                </div>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://link.springer.com/article/10.1007/s10044-021-01020-9">
              <papertitle>Harnessing emotions for depression detection</papertitle>
              </a>
              <br>
              <a href="">Sahana Prabhu Muraleedhara</a>
              <strong>Himangi Mittal</strong>,
              <a href="">Rajesh Varagani</a>,
              <a href="">Sweccha Jha</a>,
              <a href="">Shivendra Singh</a>
              <br>
              <em>Pattern Analysis and Applications Journal</em>
              <br>
              <a href="https://link.springer.com/article/10.1007/s10044-021-01020-9">Paper</a>
              <p></p>
              <p>A method for multi-modal depression detection using audio, video, and textual modalities using LSTMs. This work leverages emotions to detect an early indication of 
                depression.</p>
            </td>
          </tr>


          <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='cvpr_image'>
                    <a href="images/overview_car.png"><img style="width:120%;max-width:120%" alt="profile photo" src="images/overview_car.png" class="hoverZoomLink"></a>
                </div>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1912.00497.pdf">
              <papertitle>Just Go with the Flow: Self-Supervised Scene Flow Estimation</papertitle>
              </a>
              <br>
              <strong>Himangi Mittal</strong>,
              <a href="https://www.ri.cmu.edu/ri-people/brian-e-okorn/">Brian Okorn</a>,
              <a href="http://davheld.github.io/">David Held</a>,
              <br>
              <em>CVPR</em> 2020 <font color="red">(Oral)</font>
              <br>
              <a href="https://just-go-with-the-flow.github.io/">Project Page</a>
              /
              <a href="https://github.com/HimangiM/Just-Go-with-the-Flow-Self-Supervised-Scene-Flow-Estimation">Code</a>
              /
              <a href="https://www.youtube.com/watch?v=a5HFnDPTNLk">Video</a>
              /
              <a href="https://arxiv.org/pdf/1912.00497.pdf">PDF</a>
              <p></p>
              <p>A method of training scene flow that uses two self-supervised losses, based on nearest neighbors and cycle consistency. 
                These self-supervised losses allow us to train our method on large unlabeled autonomous driving datasets.</p>
            </td>
          </tr>


          <tr onmouseout="mipnerf_stop()" onmouseover="mipnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mipnerf_image'>
                 <a href="images/Fig-7.jpg"><img style="width:120%;max-width:120%" alt="profile photo" src="images/Fig-7.jpg" class="hoverZoomLink"></a>
              </div>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1912.00501.pdf">
                <papertitle>Interpreting Context of Images using Scene Graphs</papertitle>
              </a>
              <br>
              <strong>Himangi Mittal</strong>,
              <a href="https://www.mirlabs.org/researchers/Ajith%20Abraham.php">Ajith Abraham</a>,
              <a href="http://www.jiit.ac.in/dr-anuja-arora">Anuja Arora</a>
              <br>
              <em>International Conference on Big Data Analytics (BDA)</em>, 2019 
              <br>
              <a href="https://arxiv.org/pdf/1912.00501.pdf">arXiv</a>
              /
              <a href="https://github.com/HimangiM/Scene-Graph-Generation">Code</a>
              <p></p>
              <p>Predicted action and spatial relationships in images between objects detected by YOLO, then combining VGG-Net based visual features and 
                Word2Vec based semantic features.</p>
            </td>
          </tr> 

          <tr onmouseout="ibrnet_stop()" onmouseover="ibrnet_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='cvpr_image'>
                    <a href="images/anomaly.png"><img style="width:120%;max-width:120%" alt="profile photo" src="images/anomaly.png" class="hoverZoomLink"></a>
                </div>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/8862186">
                <papertitle>Anomaly Detection using Graph Neural Networks</papertitle>
              </a>
              <br>
              <a href="">Anshika Chaudhary</a>,
              <strong>Himangi Mittal</strong>,
              <a href="http://www.jiit.ac.in/dr-anuja-arora">Anuja Arora</a>
              <br>
              <em>International Conference on Machine Learning, Big Data, Cloud and Parallel Computing </em>, 2019
              <br>
              <a href="https://github.com/HimangiM/Anomaly_Graph_Neural_Net">code</a> 
              <p></p>
              <p>A method to capture the anomalous behavior in a social network based on degree, betweenness, and closeness of graph nodes using 
                Graph Neural Networks (GNN) in Keras.</p>
            </td>
          </tr>

          <tr onmouseout="nerv_stop()" onmouseover="nerv_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='cvpr_image'>
                    <a href="images/stwalk.png"><img style="width:120%;max-width:120%" alt="profile photo" src="images/stwalk.png" class="hoverZoomLink"></a>
                </div>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1711.04150.pdf">
                <papertitle>STWalk: Learning Trajectory Representations in Temporal Graphs</papertitle>
              </a>
              <br>
              <a href="https://supriya-gdptl.github.io/">Supriya Pandhre</a>,
              <strong>Himangi Mittal</strong>
              <a href="https://www.microsoft.com/en-us/research/people/gmanish/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fpeople%2Fgmanish%2F">Manish Gupta</a>,
              <a href="https://www.iith.ac.in/~vineethnb/">Vineeth N. Balasubramanian</a>, <br>              
              <br>
              <em>ACM India Joint International Conference on Data Science and Management of Data (CoDS-COMAD)</em>, 2018
              <br>
              <a href="https://github.com/supriya-gdptl/STWalk">Code</a> /
              <a href="https://arxiv.org/pdf/1711.04150.pdf">arXiv</a>
              <p></p>
              <p>Presents trajectory analysis of spatio-temporal graph nodes using DeepWalk algorithm in NetworkX (Python) for classication and detecting 
                changing points of interest using SVMs.</p>
            </td>
          </tr>          

<!--           <tr onmouseout="dt_stop()" onmouseover="dt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dt_image'><img src='images/DT_edge.jpg'></div>
                <img src='images/DT_image.jpg'>
              </div>
              <script type="text/javascript">
                function dt_start() {
                  document.getElementById('dt_image').style.opacity = "1";
                }

                function dt_stop() {
                  document.getElementById('dt_image').style.opacity = "0";
                }
                dt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/178Xj2PZ1w6hZJpucU-TiZOoCemJmvsVQ/view?usp=sharing">
                <papertitle>Semantic Image Segmentation with Task-Specific Edge Detection Using CNNs and a Discriminatively Trained Domain Transform</papertitle>
              </a>
              <br>
              <em>CVPR</em>, 2016
              <br>
              <a href="http://liangchiehchen.com/">Liang-Chieh Chen</a>, <strong>Jonathan T. Barron</strong>, <a href="http://ttic.uchicago.edu/~gpapan/">George Papandreou</a>, <a href="http://www.cs.ubc.ca/~murphyk/">Kevin Murphy</a>, <a href="http://www.stat.ucla.edu/~yuille/">Alan L. Yuille</a>
              <br>
              <a href="data/Chen2016.bib">bibtex</a> /
              <a href="http://liangchiehchen.com/projects/DeepLab.html">project page</a> /
              <a href="https://bitbucket.org/aquariusjay/deeplab-public-ver2">code</a>
              <p></p>
              <p>By integrating an edge-aware filter into a convolutional neural network we can learn an edge-detector while improving semantic segmentation.</p>
            </td>
          </tr>

          <tr onmouseout="ccc_stop()" onmouseover="ccc_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ccc_image'><img src='images/ccc_after.jpg'></div>
                <img src='images/ccc_before.jpg'>
              </div>
              <script type="text/javascript">
                function ccc_start() {
                  document.getElementById('ccc_image').style.opacity = "1";
                }

                function ccc_stop() {
                  document.getElementById('ccc_image').style.opacity = "0";
                }
                ccc_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1id74VNDL8ACrrWf6vYgN2M4kS8gd4n7w/view?usp=sharing">
                <papertitle>Convolutional Color Constancy</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>
              <br>
              <em>ICCV</em>, 2015
              <br>
              <a href="https://drive.google.com/file/d/1vO3sVOMihmpNqsuASeR46Y_iME0lOANR/view?usp=sharing">supplement</a> / <a href="data/BarronICCV2015.bib">bibtex</a> / <a href="https://youtu.be/saHwKY9rfx0">video</a> (or <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmalBNUzlENUJSVDg/view?usp=sharing">mp4</a>)
              <p></p>
              <p>By framing white balance as a chroma localization task we can discriminatively learn a color constancy model that beats the state-of-the-art by 40%.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/Shelhamer2015.jpg'>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1stygV71uBruD7Ck9CaAQr7nREvr3DtUL/view?usp=sharing">
                <papertitle>Scene Intrinsics and Depth from a Single Image</papertitle>
              </a>
              <br>
              <a href="http://imaginarynumber.net/">Evan Shelhamer</a>, <strong>Jonathan T. Barron</strong>, <a href="http://www.eecs.berkeley.edu/%7Etrevor/">Trevor Darrell</a>
              <br>
              <em>ICCV Workshop</em>, 2015
              <br>
              <a href="data/Shelhamer2015.bib">bibtex</a>
              <p></p>
              <p>The monocular depth estimates produced by fully convolutional networks can be used to inform intrinsic image estimation.</p>
            </td>
          </tr>

          <tr bgcolor="#ffffd0" onmouseout="defocus_stop()" onmouseover="defocus_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div id='lens_blurry' class='hidden'><img src="images/BarronCVPR2015_anim.gif"></div>
              <div id='lens_sharp'>
                <a href="images/BarronCVPR2015_anim.gif"><img src="images/BarronCVPR2015_still.jpg"></a>
              </div>
              <script type="text/javascript">
                function defocus_start() {
                  document.getElementById('lens_blurry').style.display = 'inline';
                  document.getElementById('lens_sharp').style.display = 'none';
                }

                function defocus_stop() {
                  document.getElementById('lens_blurry').style.display = 'none';
                  document.getElementById('lens_sharp').style.display = 'inline';
                }
                defocus_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1R4RdaBZIs-uJobhIFs9yKf3jIsaHQNH0/view?usp=sharing">
                <papertitle>Fast Bilateral-Space Stereo for Synthetic Defocus</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>, <a href="http://people.csail.mit.edu/abadams/">Andrew Adams</a>, <a href="http://people.csail.mit.edu/yichangshih/">YiChang Shih</a>, <a href="http://carlos-hernandez.org/">Carlos Hern&aacutendez</a>
              <br>
              <em>CVPR</em>, 2015 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://drive.google.com/file/d/125qgMdqeT1vojMIijIKcOF099LjUgUOL/view?usp=sharing">abstract</a> /
              <a href="https://drive.google.com/file/d/1HGGvVOGxmPjvgdK5q3UD1Qb5Nttg6kq9/view?usp=sharing">supplement</a> /
              <a href="data/BarronCVPR2015.bib">bibtex</a> /
              <a href="http://techtalks.tv/talks/fast-bilateral-space-stereo-for-synthetic-defocus/61624/">talk</a> /
              <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmSzZZdUJSMllSUkE/view?usp=sharing">keynote</a> (or <a href="https://drive.google.com/open?id=0B4nuwEMaEsnmZ1ZXUzBCWDJYeFU">PDF</a>)
              <p></p>
              <p>By embedding a stereo optimization problem in "bilateral-space" we can very quickly solve for an edge-aware depth map, letting us render beautiful depth-of-field effects.</p>
              <p>This technology is used by the <a href="http://googleresearch.blogspot.com/2014/04/lens-blur-in-new-google-camera-app.html">Google Camera "Lens Blur"</a> feature. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/PABMM2015.jpg" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/1503.00848" id="MCG_journal">
                <papertitle>Multiscale Combinatorial Grouping for Image Segmentation and Object Proposal Generation</papertitle>
              </a>
              <br>
              <a href="http://imatge.upc.edu/web/people/jordi-pont-tuset">Jordi Pont-Tuset</a>, <a href="http://www.cs.berkeley.edu/~arbelaez/">Pablo Arbel&aacuteez</a>, <strong>Jonathan T. Barron</strong>, <a href="http://imatge.upc.edu/web/ferran">Ferran Marqu&eacutes</a>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
              <br>
              <em>TPAMI</em>, 2017
              <br>
              <a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> /
              <a href="data/PontTusetTPAMI2017.bib">bibtex</a> /
              <a href="https://drive.google.com/file/d/1AiB78Fy7QVA3KqgcooyzMAC5L8HhNzjz/view?usp=sharing">fast eigenvector code</a>
              <p></p>
              <p>We produce state-of-the-art contours, regions and object candidates, and we compute normalized-cuts eigenvectors 20&times faster.</p>
              <p>This paper subsumes our CVPR 2014 paper.</p>
            </td>
          </tr>

          <tr bgcolor="#ffffd0" onmouseout="sirfs_stop()" onmouseover="sirfs_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='sirfs_image'>
                  <a href="images/Estee.png"><img src='images/Estee_160.png' style="border-style: none"></a>
                </div>
                <a href="images/Estee.png"><img src='images/Estee_160_prodB2.png' style="border-style: none"></a>
              </div>
              <script type="text/javascript">
                function sirfs_start() {
                  document.getElementById('sirfs_image').style.opacity = "1";
                }

                function sirfs_stop() {
                  document.getElementById('sirfs_image').style.opacity = "0";
                }
                sirfs_stop()
              </script>
            </td>
            <td width="75%" valign="middle">
              <p>
                <a href="https://arxiv.org/abs/2010.03592" id="SIRFS">
                  <papertitle>Shape, Illumination, and Reflectance from Shading</papertitle>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
                <br>
                <em>TPAMI</em>, 2015
                <br>
                <a href="data/BarronMalikTPAMI2015.bib">bibtex</a> / <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmVWpfa19mbUxIYW8/view?usp=sharing">keynote</a> (or <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmazJvLXJUb0NuM1U/view?usp=sharing">powerpoint</a>, <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmTDBUWE96VHJndjg/view?usp=sharing">PDF</a>) / <a href="http://www.youtube.com/watch?v=NnePYprvFvA">video</a> / <a href="https://drive.google.com/file/d/1vg9Rb-kBntSTnTCzVgFlskkPXvTB_5aq/view?usp=sharing">code &amp; data</a> / <a href="https://drive.google.com/file/d/11X5Zfjy7Q7oP_V2rtqy2f5-x9YgQUAFd/view?usp=sharing">kudos</a>
              </p>
              <p>
                We present <strong>SIRFS</strong>, which can estimate shape, chromatic illumination, reflectance, and shading from a single image of an masked object.
              </p>
              <p>
                This paper subsumes our CVPR 2011, CVPR 2012, and ECCV 2012 papers.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ArbalaezCVPR2014.jpg" alt="ArbalaezCVPR2014" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://drive.google.com/file/d/1M0wijHY134F9ETBgO8mjeuKUSblTRLG0/view?usp=sharing">
                <papertitle>Multiscale Combinatorial Grouping</papertitle>
              </a>
              <br>
              <a href="http://www.cs.berkeley.edu/~arbelaez/">Pablo Arbel&aacuteez</a>, <a href="http://imatge.upc.edu/web/people/jordi-pont-tuset">Jordi Pont-Tuset</a>, <strong>Jonathan T. Barron</strong>, <a href="http://imatge.upc.edu/web/ferran">Ferran Marqu&eacutes</a>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
              <br>
              <em>CVPR</em>, 2014
              <br>
              <a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> /
              <a href="data/ArbelaezCVPR2014.bib">bibtex</a>
              <p>This paper is subsumed by <a href="#MCG_journal">our journal paper</a>.</p>
            </td>
          </tr>

          <tr onmouseout="flyspin_stop()" onmouseover="flyspin_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div id='flyspin' class='hidden'><img src="images/BarronICCV2013_160.gif"></div>
              <div id='flystill'>
                <a href="images/BarronICCV2013.gif"><img src="images/BarronICCV2013_160.jpg"></a>
              </div>
              <script type="text/javascript">
                function flyspin_start() {
                  document.getElementById('flyspin').style.display = 'inline';
                  document.getElementById('flystill').style.display = 'none';
                }

                function flyspin_stop() {
                  document.getElementById('flyspin').style.display = 'none';
                  document.getElementById('flystill').style.display = 'inline';
                }
                flyspin_stop()
              </script>
            </td>
            <td width="75%" valign="middle">
              <a href="https://drive.google.com/file/d/1shvItvx_8Sb8QNXhrOXkuRmx2618iwNJ/view?usp=sharing">
                <papertitle>Volumetric Semantic Segmentation using Pyramid Context Features</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~arbelaez/">Pablo Arbel&aacuteez</a>, <a href="http://big.lbl.gov/">Soile V. E. Ker&aumlnen</a>, <a href="http://www.lbl.gov/gsd/biggin.html">Mark D. Biggin</a>,
              <br> <a href="http://dwknowles.lbl.gov/">David W. Knowles</a>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
              <br>
              <em>ICCV</em>, 2013
              <br>
              <a href="https://drive.google.com/file/d/1htiLpMAcYLtuBthmAb4XHnOYxUbkfnqR/view?usp=sharing">supplement</a> /
              <a href="https://drive.google.com/file/d/1qoYeFNa443myn2SfcdhmCsYBqE9xQrPD/view?usp=sharing">poster</a> /
              <a href="data/BarronICCV2013.bib">bibtex</a> / <a href="http://www.youtube.com/watch?v=Y56-FcfnlVA&hd=1">video 1</a> (or <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmZ1ZLaHdQYzAxNlU/view?usp=sharing">mp4</a>) / <a href="http://www.youtube.com/watch?v=mvRoYuP6-l4&hd=1">video 2</a> (or <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmZ1ZLaHdQYzAxNlU/view?usp=sharing">mp4</a>) / <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmSF9YdWJjQmh4QW8/view?usp=sharing">code &amp; data</a>
              <p>
                We present a technique for efficient per-voxel linear classification, which enables accurate and fast semantic segmentation of volumetric Drosophila imagery.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/3DSP_160.jpg" alt="3DSP" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmbG1tOGIta3N1Wjg/view?usp=sharing" id="3DSP">
                <papertitle>3D Self-Portraits</papertitle>
              </a>
              <br>
              <a href="http://www.hao-li.com/">Hao Li</a>, <a href="http://www.evouga.com/">Etienne Vouga</a>, Anton Gudym, <a href="http://www.cs.princeton.edu/~linjiel/">Linjie Luo</a>, <strong>Jonathan T. Barron</strong>, Gleb Gusev
              <br>
              <em>SIGGRAPH Asia</em>, 2013
              <br>
              <a href="http://www.youtube.com/watch?v=DmUkbZ0QMCA">video</a> / <a href="http://shapify.me/">shapify.me</a> / <a href="data/3DSP_siggraphAsia2013.bib">bibtex</a>
              <p>Our system allows users to create textured 3D models of themselves in arbitrary poses using only a single 3D sensor.</p>
            </td>
          </tr>

          <tr onmouseout="rgbd_stop()" onmouseover="rgbd_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div id='rgbd_anim' class='hidden'><img src="images/SceneSIRFS.gif"></div>
              <div id='rgbd_still'><img src="images/SceneSIRFS-still.jpg"></div>
              <script type="text/javascript">
                function rgbd_start() {
                  document.getElementById('rgbd_anim').style.display = 'inline';
                  document.getElementById('rgbd_still').style.display = 'none';
                }

                function rgbd_stop() {
                  document.getElementById('rgbd_anim').style.display = 'none';
                  document.getElementById('rgbd_still').style.display = 'inline';
                }
                rgbd_stop()
              </script>
            </td>
            <td width="75%" valign="middle">
              <a href="https://drive.google.com/file/d/1snypSLhzC0jXCchJRsWpcDZ7Es5hDmXo/view?usp=sharing">
                <papertitle>Intrinsic Scene Properties from a Single RGB-D Image</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
              <br>
              <em>CVPR</em>, 2013 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://drive.google.com/file/d/1cLUw72WpgdZ_3TQAjJABdgywqjBfn_Mq/view?usp=sharing">supplement</a> / <a href="data/BarronMalikCVPR2013.bib">bibtex</a> / <a href="http://techtalks.tv/talks/intrinsic-scene-properties-from-a-single-rgb-d-image/58614/">talk</a> / <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmWW1CZGJPbi12R0k/view?usp=sharing">keynote</a> (or <a href="https://drive.google.com/file/d/19q3EFf6GIb4UFcCN2DVU2jVKpxRj5kxf/view?usp=sharing">powerpoint</a>, <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmMzQ4ZVp1SWdnVkk/view?usp=sharing">PDF</a>) / <a href="https://drive.google.com/open?id=1ZbPScVA6Efqd-ESvojl92sw8K-82Xxry">code &amp; data</a>
              <p>By embedding mixtures of shapes &amp; lights into a soft segmentation of an image, and by leveraging the output of the Kinect, we can extend SIRFS to scenes.
                <br>
                <br>TPAMI Journal version: <a href="https://drive.google.com/file/d/1iQiUxZvjPPnb8rFCwXYesTgFSRk7mkAq/view?usp=sharing">version</a> / <a href="data/BarronMalikTPAMI2015B.bib">bibtex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/Boundary.jpg" alt="Boundary_png" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://drive.google.com/file/d/1H4YPovfrvcce3HGMEhidwU2l2fTcNR5y/view?usp=sharing">
                <papertitle>Boundary Cues for 3D Object Shape Recovery</papertitle>
              </a>
              <br>
              <a href="http://www.kevinkarsch.com/">Kevin Karsch</a>,
              <a href="http://web.engr.illinois.edu/~liao17/">Zicheng Liao</a>,
              <a href="http://web.engr.illinois.edu/~jjrock2/">Jason Rock</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://www.cs.illinois.edu/homes/dhoiem/">Derek Hoiem</a>
              <br>
              <em>CVPR</em>, 2013
              <br>
              <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmLUQ5SVJTcUZIYXc/view?usp=sharing">supplement</a> / <a href="data/KarschCVPR2013.bib">bibtex</a>
              <p>Boundary cues (like occlusions and folds) can be used for shape reconstruction, which improves object recognition for humans and computers.</p>
            </td>
          </tr>

          <tr onmouseout="eccv12_stop()" onmouseover="eccv12_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div id='eccv12_anim' class='hidden'>
                <a href="https://drive.google.com/file/d/1brxb58CfRPe7KEER4Q_fYS9B_J-hiS0t/view?usp=sharing"><img src="images/ECCV2012_small.gif"></a>
              </div>
              <div id='eccv12_still'><img src="images/ECCV2012_still.jpg"></div>
              <script type="text/javascript">
                function eccv12_start() {
                  document.getElementById('eccv12_anim').style.display = 'inline';
                  document.getElementById('eccv12_still').style.display = 'none';
                }

                function eccv12_stop() {
                  document.getElementById('eccv12_anim').style.display = 'none';
                  document.getElementById('eccv12_still').style.display = 'inline';
                }
                eccv12_stop()
              </script>
            </td>
            <td width="75%" valign="middle">
              <a href="https://drive.google.com/file/d/1NczR4pJ-s0YBjCe0rCevMt8IM5JPuUrc/view?usp=sharing">
                <papertitle>Color Constancy, Intrinsic Images, and Shape Estimation</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
              <br>
              <em>ECCV</em>, 2012
              <br>
              <a href="https://drive.google.com/file/d/1zuxhWZ3i6THvuRRBeE7dM_BJfDxO72Fq/view?usp=sharing">supplement</a> /
              <a href="data/BarronMalikECCV2012.bib">bibtex</a> /
              <a href="https://drive.google.com/file/d/12x8mhqpFsA6p0u6ZQW-ieRKF8hlQBKKe/view?usp=sharing">poster</a> /
              <a href="http://www.youtube.com/watch?v=NnePYprvFvA">video</a>
              <p>This paper is subsumed by <a href="#SIRFS">SIRFS</a>.</p>
            </td>
          </tr>

          <tr onmouseout="cvpr12_stop()" onmouseover="cvpr12_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" style="height: 120px">
                <div class="two" id='cvpr12_image' style="height: 120px">
                  <img src='images/BarronCVPR2012_after.jpg' style="border-style: none">
                </div>
                <img src='images/BarronCVPR2012_before.jpg' style="border-style: none">
              </div>
              <script type="text/javascript">
                function cvpr12_start() {
                  document.getElementById('cvpr12_image').style.opacity = "1";
                }

                function cvpr12_stop() {
                  document.getElementById('cvpr12_image').style.opacity = "0";
                }
                cvpr12_stop()
              </script>
            </td>
            <td width="75%" valign="middle">
              <a href="https://drive.google.com/file/d/17RfINbE2dr2EjXp9MtGO0MHJLQmQVhvT/view?usp=sharing">
                <papertitle>Shape, Albedo, and Illumination from a Single Image of an Unknown Object</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
              <br>
              <em>CVPR</em>, 2012
              <br>
              <a href="https://drive.google.com/file/d/1Im_bUI42AP9VPoNtsjLajvtLRiwv39k3/view?usp=sharing">supplement</a> /
              <a href="data/BarronMalikCVPR2012.bib">bibtex</a> /
              <a href="https://drive.google.com/file/d/1IAlSF4k3_CEL9dfbaMiNTFPBoEkLhsRl/view?usp=sharing">poster</a>
              <p>This paper is subsumed by <a href="#SIRFS">SIRFS</a>.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/B3DO.jpg" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://drive.google.com/file/d/1_S8EQyngbHQrB415o0XkQ4V9SMzdEgWT/view?usp=sharing">
                <papertitle>A Category-Level 3-D Object Dataset: Putting the Kinect to Work</papertitle>
              </a>
              <br>
              <a href="http://www.eecs.berkeley.edu/%7Eallie/">Allison Janoch</a>,
              <a href="http://sergeykarayev.com/">Sergey Karayev</a>,
              <a href="http://www.eecs.berkeley.edu/%7Ejiayq/">Yangqing Jia</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://www.cs.berkeley.edu/%7Emfritz/">Mario Fritz</a>,
              <a href="http://www.icsi.berkeley.edu/%7Esaenko/">Kate Saenko</a>,
              <a href="http://www.eecs.berkeley.edu/%7Etrevor/">Trevor Darrell</a>
              <br>
              <em>ICCV 3DRR Workshop</em>, 2011
              <br>
              <a href="data/B3DO_ICCV_2011.bib">bibtex</a> /
              <a href="https://drive.google.com/file/d/1qf4-U5RhSw12O7gzQwW66SMQhs2FWYDW/view?usp=sharing">"smoothing" code</a>
              <p>We present a large RGB-D dataset of indoor scenes and investigate ways to improve object detection using depth information.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/safs.jpg" alt="safs_small" width="160" height="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://drive.google.com/file/d/1EZTOO5xezLYcyIFgAzs4KuZFLbTcwTDH/view?usp=sharing">
                <papertitle>High-Frequency Shape and Albedo from Shading using Natural Image Statistics</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
              <br>
              <em>CVPR</em>, 2011
              <br>
              <a href="data/BarronMalikCVPR2011.bib">bibtex</a>
              <p>This paper is subsumed by <a href="#SIRFS">SIRFS</a>.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/fast_texture.jpg" alt="fast-texture" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://drive.google.com/file/d/1rc05NatkQVmUDlGCAYcHSrvAzTpU9knT/view?usp=sharing">
                <papertitle>Discovering Efficiency in Coarse-To-Fine Texture Classification</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
              <br>
              <em>Technical Report</em>, 2010
              <br>
              <a href="data/BarronTR2010.bib">bibtex</a>
              <p>A model and feature representation that allows for sub-linear coarse-to-fine semantic segmentation.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/prl.jpg" alt="prl" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://drive.google.com/file/d/13rVuJpcytRdLYCnKpq46g7B7IzSrPQ2P/view?usp=sharing">
                <papertitle>Parallelizing Reinforcement Learning</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>, <a href="http://www.eecs.berkeley.edu/~dsg/">Dave Golland</a>, <a href="http://www.cs.berkeley.edu/~nickjhay/">Nicholas J. Hay</a>
              <br>
              <em>Technical Report</em>, 2009
              <br>
              <a href="data/BarronPRL2009.bib">bibtex</a>
              <p>Markov Decision Problems which lie in a low-dimensional latent space can be decomposed, allowing modified RL algorithms to run orders of magnitude faster in parallel.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/bd_promo.jpg" alt="blind-date" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://drive.google.com/file/d/1PQjzKgFcrAesMIDJr-WDlCwuGUxZJZwO/view?usp=sharing">
                <papertitle>Blind Date: Using Proper Motions to Determine the Ages of Historical Images</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>, <a href="http://cosmo.nyu.edu/hogg/">David W. Hogg</a>, <a href="http://www.astro.princeton.edu/~dstn/">Dustin Lang</a>, <a href="http://cs.nyu.edu/~roweis/">Sam Roweis</a>
              <br>
              <em>The Astronomical Journal</em>, 136, 2008
              <p>Using the relative motions of stars we can accurately estimate the date of origin of historical astronomical images.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/clean_promo.jpg" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://drive.google.com/file/d/1YvRx-4hrZoCk-nl6OgVJZlHAqOiN5hWq/view?usp=sharing">
                <papertitle>Cleaning the USNO-B Catalog Through Automatic Detection of Optical Artifacts</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>, <a href="http://stumm.ca/">Christopher Stumm</a>, <a href="http://cosmo.nyu.edu/hogg/">David W. Hogg</a>, <a href="http://www.astro.princeton.edu/~dstn/">Dustin Lang</a>, <a href="http://cs.nyu.edu/~roweis/">Sam Roweis</a>
              <br>
              <em>The Astronomical Journal</em>, 135, 2008
              <p>We use computer vision techniques to identify and remove diffraction spikes and reflection halos in the USNO-B Catalog.</p>
              <p>In use at <a href="http://www.astrometry.net">Astrometry.net</a></p>
            </td>
          </tr>

        </tbody></table> -->

<!--         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Service</heading>
            </td>
          </tr>
        </tbody></table> -->
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
<!--           <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
              <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair, CVPR 2021</a>
              <br><br>
              <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
              <br><br>
              <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
            </td>
          </tr> -->
<!--           <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cs188.jpg" alt="cs188">
            </td>
            <td width="75%" valign="center">
              <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
              <br>
              <br>
              <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
              <br>
              <br>
              <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
            </td>
          </tr> -->
        </tbody>
      </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://github.com/jonbarron/jonbarron_website">Source Code</a>                
                <br>
<!--                 Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page. -->
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
